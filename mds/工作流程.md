# 工作流程

## 预先准备
需要准备一个文件夹，用来存放生成的数据(记录)文件。

> 警告：不要在准备整理的文件夹目录下运行此文件，会对每次更新时产生的新记录文件进行无限哈希，每执行一次，条目都会增加！

而后切换到文件夹目录下，执行"init.py"文件，会自动在文件夹下生成若干记录文件，请保持它们不被人工修改。

## 下载文件后
当下载文件后，将下载的所有文件放入一个文件夹中

> tips:这一步不会保证文件不出现复制错误，因此请尽量进行同分区移动，这样仅仅会移动文件系统目录项，不会产生复制错误

调用afterdownload.py脚本，脚本会计算出文件夹中所有文件的哈希值，而后，将文件列表与写在downloadFile文件夹中的最新文件 *(这个文件被命名成"new.txt")* 进行合并，在合并过程中，对每个文件：如果文件的哈希值不同，显然是不同的文件，直接新建一个表项存入，如果哈希值相同，需要对整个文件进行逐字节比对，存在三种可能： 

* 对于文件路径相同的文件，一般为重复对一个文件夹执行了两次脚本，这样的文件会在并入时进行忽略
* 对于文件每个字节都相同的文件，会将文件的originPath/unzip/zip三项与原本存在的的文件合并，并将不合并的表项做单独记录，供之后生成文件使用。
* 对于实质不相同的文件，会使用类似哈希冲突解决办法，在其后记录若干位的数据位（一位起记，上不封顶）。

在进行过文件的合并后，哈希值不同的文件会被记录到相同的文件中，而相同的文件会被存在一个文件列表中，相同的文件会被redirect.txt文件取代。

最后，所有的文件索引项会被写入到新的"new.txt"文件中，同时会拷贝一份至“年_月_日_时_分_秒_.txt”中。

> 在回写时，旧的记录中的文件也会被写入到新的记录中。

> 经过这样的操作，全部的文件的哈希值都会不相同

## 手动整理和压缩文件的处理（正在写）

在文件的初始哈希被记录之后，请手动整理文件，手动整理文件时，请新建一个文件夹，在文件夹中，存在“delete”，“tidy”两个文件夹。“delete”文件夹用来存储要被删除的文件，例如缓存文件，而“tidy”文件夹则保存已经整理好的文件夹。

将需要删除的文件放入“delete”文件夹，对于redirect文件，不需要的（例如广告，临时缓存等）也可以放到delete文件夹。如果redirect的内容需要被分开，手动分离并保存第一行至其余两个文件夹即可。

同时进行压缩文件的整理

> 不会，也无法对解压过程做任何的正确性校验，请保证解压流程的正确性，不过，如果肯解压两遍分别命名为unzip1/unzip2和zip1/zip2的话，还是可以验证两次解压是否一致的。

在大文件夹下新建两个文件夹，分别命名为zip和unzip，这两个文件夹下各有若干小文件夹，小文件夹的命名不重要。

zip的文件夹下的每个小文件夹内有：

1. 一个压缩文件，即要解压的文件
2. 一个文件夹，保存所有解压出来的文件

unzip文件夹下的每个小文件夹内有：

1. 一个压缩文件，压缩过后的文件
2. 一个文件夹，保存所有压缩前的文件

而后，将这些解压出来的文件合并到它应该在的位置，如果存在重复文件，直接删除也不要紧。

调用aftertidy脚本，脚本会计算出zip和unzip文件夹下所有文件的解压关系，并以哈希值的形式记录在“unzips”文件夹中中的“new.txt”中。

而后，会计算整理完成的文件的哈希，在downloads文件中删除这些文件，转而记录在“tidys”文件夹中的“new.txt”中，同时，对文件相同的，会第二轮生成redirect.txt。

最后请手动整理一遍，消除不想要的文件。


## 文件的归档

将储存池上线，然后运行beforestore.py脚本，脚本会加载tidys文件夹中的最新记录，与final文件夹对比，找出文件确实相同的项，并生成redirect。

最后手动移动文件，运行afterstore脚本，脚本会找到存在于储存池中的文件，并且比较出不存在于final中的文件，计算哈希值，从tidys中提取出相应的文件，归档。

## 文件的移动

调用move脚本，声明源仓库和目的仓库，即可对比并校验，还能顺便重写路径。



